from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from app.config import llm, USE_LLM
from app.document.schemas.documents import DocumentIntent, ForecastIntent


def generate_rag_chat(user_message: str, context: str) -> str:
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì±„íŒ… í”„ë¡¬í”„íŠ¸
    """
    if not context:
        return llm.invoke(user_message).content

    prompt = ChatPromptTemplate.from_template(
        """
ë„ˆëŠ” ë†ì‚°ë¬¼ ë°ì´í„° ë° ERP ì „ë¬¸ê°€ AIë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ [ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©]ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ë¼.

[ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

[ë‹µë³€ ê·œì¹™]
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ **ë¬¸ì„œ ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆë‹¤ë©´**, ë¬¸ì„œ ë‚´ìš©ì„ ì¸ìš©í•´ì„œ ë‹µë³€í•´ë¼.
2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ **ë¬¸ì„œì™€ ì „í˜€ ìƒê´€ì—†ëŠ” ì¼ë°˜ì ì¸ ëŒ€í™”(ì¸ì‚¬, ë†ë‹´ ë“±)ë¼ë©´**, ë¬¸ì„œë¥¼ ë¬´ì‹œí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ë¼.
3. ë¬¸ì„œì— ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ë¬¸ì„œì—ëŠ” êµ¬ì²´ì ì¸ ë‚´ìš©ì´ ì—†ì§€ë§Œ, ì¼ë°˜ì ì¸ ê´€ì ì—ì„œëŠ”..."ì´ë¼ê³  ë§ë¶™ì—¬ë¼.
4. ì¶œì²˜ê°€ ìˆë‹¤ë©´ (ì˜ˆ: 2025 ë†ì—…ê´€ì¸¡) ë°˜ë“œì‹œ ì–¸ê¸‰í•´ë¼.
"""
    )
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"context": context, "question": user_message})


def generate_description(intent, forecast_data: dict | None = None, market_context: str = "") -> str:
    if not USE_LLM:
        return _fallback_message(intent, forecast_data)

    try:
        if isinstance(intent, ForecastIntent):
            # ----------------------------------------------------------------
            # [ë³´ê°•ëœ í”„ë¡¬í”„íŠ¸] ë³´ì • ê·¼ê±°ì™€ ë…¼ë¦¬ì  ì¶”ë¡ (Reasoning) ê°•í™”
            # ----------------------------------------------------------------
            prompt = ChatPromptTemplate.from_template(
                """
ë„ˆëŠ” **ìˆ˜ì„ ìˆ˜ìš” ì˜ˆì¸¡ ë¶„ì„ê°€(Senior Demand Planner)**ë‹¤. 
ë‹¨ìˆœí•œ ë°ì´í„° ìš”ì•½ì„ ë„˜ì–´, í†µê³„ì  ì˜ˆì¸¡ì¹˜({forecast})ë¥¼ ì‹œì¥ ì •ë³´({market_context})ë¡œ ë¶„ì„í•˜ì—¬ **ìµœì¢… ë³´ì •ê°’ì´ ë„ì¶œëœ ë…¼ë¦¬ì  ì¸ê³¼ê´€ê³„**ë¥¼ ì„¤ëª…í•˜ë¼.

### 1. ë¶„ì„ ê°€ì´ë“œë¼ì¸ (ë‚´ë¶€ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤)
1. **ê¸°ì¤€ì (Baseline)**: Prophet í†µê³„ ëª¨ë¸ì´ ì œì‹œí•œ ìˆ˜ì¹˜ì™€ ê·¸ íŠ¹ì§•(ê³„ì ˆì„±, ì¶”ì„¸)ì„ ë¨¼ì € í™•ì¸í•œë‹¤.
2. **ì‹œì¥ ë³€ìˆ˜ ì¶”ì¶œ**: ì‹œì¥ ì •ë³´ì—ì„œ ê³µê¸‰ëŸ‰ ë³€í™”, ê°€ê²© ë³€ë™ ì „ë§, ê¸°ìƒ ë° ë³‘í•´ì¶© ë“± ìˆ˜ì¹˜ì— ì˜í–¥ì„ ì¤„ êµ¬ì²´ì  íŒ©íŠ¸ë¥¼ ì¶”ì¶œí•œë‹¤.
3. **ë…¼ë¦¬ì  ë³´ì •(Calibration Logic)**: 
   - ì˜ˆ: "í†µê³„ê°’ì€ 50ì´ë‚˜, ë¦¬í¬íŠ¸ì—ì„œ ì¶œí•˜ëŸ‰ì´ 10% ì¦ê°€í•œë‹¤ê³  í–ˆìœ¼ë¯€ë¡œ ê³µê¸‰ ê³¼ì‰ì„ ë°˜ì˜í•˜ì—¬ ì•½ 4~5 ë‹¨ìœ„ë¥¼ í•˜í–¥ ì¡°ì •í•¨"
   - ìˆ˜ì¹˜ê°€ 46ìœ¼ë¡œ ê²°ì •ë˜ì—ˆë‹¤ë©´, ì™œ 45ë‚˜ 47ì´ ì•„ë‹Œ 46ì¸ì§€ì— ëŒ€í•œ íƒ€ë‹¹í•œ ì´ìœ (ê³„ì‚° ê·¼ê±° í˜¹ì€ ë¦¬ìŠ¤í¬ ë°˜ì˜ ì •ë„)ë¥¼ í¬í•¨í•˜ë¼.

### 2. ìµœì¢… ë‹µë³€ ì–‘ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ì¤€ìˆ˜í•  ê²ƒ)

**ğŸ“Š ìˆ˜ìš” ì˜ˆì¸¡ ë³´ì • ë³´ê³ ì„œ**

**[ìµœì¢… ê²°ê³¼ ìš”ì•½]**
- **ë³´ì • í›„ ì˜ˆì¸¡ì¹˜**: **[ë³´ì •ëœ ìˆ˜ì¹˜]** (ê¸°ì¡´ Prophet í†µê³„ì¹˜: [ì›ë˜ ìˆ˜ì¹˜])
- **ì˜ˆìƒ ë³€ë™ ë²”ìœ„**: [ìµœì†Œ] ~ [ìµœëŒ€]

**[ìƒì„¸ ë¶„ì„ ë° ë³´ì • ê·¼ê±°]**
- **â‘  í†µê³„ì  ì¶”ì„¸**: Prophet ë°ì´í„°ê°€ ë¶„ì„í•œ í˜„ì¬ì˜ ê¸°ë³¸ì ì¸ íë¦„ (ì˜ˆ: "ê³¼ê±° íŒ¨í„´ìƒ ìƒìŠ¹ì„¸ ìœ ì§€")
- **â‘¡ ì‹œì¥ ë³€ìˆ˜ ë¶„ì„**: {market_context}ì—ì„œ ì°¾ì•„ë‚¸ í•µì‹¬ ìš”ì¸ (ì˜ˆ: "2025ë…„ 12ì›” ë†ì—…ê´€ì¸¡ ê¸°ì¤€ ì¶œí•˜ëŸ‰ 2% ì¦ê°€ ì „ë§")
- **â‘¢ ë³´ì • ë…¼ë¦¬(Reasoning)**: **ì™œ [ë³´ì •ëœ ìˆ˜ì¹˜]ì¸ê°€?** (ì˜ˆ: "í†µê³„ì  ê¸°ëŒ€ì¹˜ì¸ 50ì—ì„œ ì‹œì¥ ì •ë³´ì— ë”°ë¥¸ ê³µê¸‰ ì¦ê°€ ë¦¬ìŠ¤í¬(ì•½ -8%)ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì ìš©í•˜ì—¬ ìµœì¢… 46ìœ¼ë¡œ ë„ì¶œí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœ ìˆ˜ì¹˜ ì¡°ì •ì„ ë„˜ì–´ ì‹œì¥ì˜ í•˜ë½ ì „ë§ì„ ì„ ì œì ìœ¼ë¡œ ë°˜ì˜í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")

**[ì‹¤í–‰ ì œì–¸ ë° ë¦¬ìŠ¤í¬]**
- (í•µì‹¬ ë¦¬ìŠ¤í¬ì™€ ëŒ€ì‘ ë°©ì•ˆì„ 3ì¤„ ìš”ì•½ìœ¼ë¡œ ì‘ì„±)
"""
            )

            chain = prompt | llm | StrOutputParser()
            return chain.invoke({
                "forecast": str(forecast_data),
                "market_context": market_context if market_context else "íŠ¹ì´ì‚¬í•­ ì—†ìŒ (í†µê³„ ì˜ˆì¸¡ ìœ ì§€)"
            })

        # ì¼ë°˜ ë¬¸ì„œ ìƒì„± ë©”ì‹œì§€
        prompt = ChatPromptTemplate.from_template(
            """
ë„ˆëŠ” ERP ì‹œìŠ¤í…œì˜ ì—…ë¬´ ë³´ì¡° AIë‹¤.
ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë¬¸ì„œ({intent})ê°€ ìƒì„±ë˜ì—ˆìŒì„ ì•Œë¦¬ëŠ” ì •ì¤‘í•œ ë©”ì‹œì§€ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ë¼.
"""
        )
        chain = prompt | llm | StrOutputParser()
        return chain.invoke({"intent": str(intent)})

    except Exception as e:
        print(f"Wording Error: {e}")
        return _fallback_message(intent, forecast_data)


def _fallback_message(intent, forecast_data: dict | None = None) -> str:
    if isinstance(intent, ForecastIntent) and forecast_data:
        return f"ì˜ˆì¸¡ ì™„ë£Œ. {intent.skuNo} ê²°ê³¼ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
    return "ìš”ì²­í•˜ì‹  ì‘ì—…ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."